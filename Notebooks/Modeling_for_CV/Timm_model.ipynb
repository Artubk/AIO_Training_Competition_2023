{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Fv-Q60OMPoCn"},"outputs":[],"source":["!git clone https://github.com/anminhhung/small_dog_cat_dataset"]},{"cell_type":"code","source":["!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 torchaudio==0.11.0 --extra-index-url https://download.pytorch.org/whl/cu113"],"metadata":{"id":"CYEj6zS2p92l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install mmcv==1.3.9"],"metadata":{"id":"U9175xf60pvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install git+https://github.com/rwightman/pytorch-image-models.git"],"metadata":{"id":"U0VInfQ6s2S3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688044776135,"user_tz":-420,"elapsed":14639,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"43fcfff2-c868-4bfd-d3ad-196fbcfa0ba8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/rwightman/pytorch-image-models.git\n","  Cloning https://github.com/rwightman/pytorch-image-models.git to /tmp/pip-req-build-9wnqlome\n","  Running command git clone --filter=blob:none --quiet https://github.com/rwightman/pytorch-image-models.git /tmp/pip-req-build-9wnqlome\n","  Resolved https://github.com/rwightman/pytorch-image-models.git to commit c241081251323dfc5e8dc799d49740c48cc9096f\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm==0.9.3.dev0) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.9.3.dev0) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.3.dev0) (6.0)\n","Collecting huggingface-hub (from timm==0.9.3.dev0)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm==0.9.3.dev0)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.3.dev0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm==0.9.3.dev0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm==0.9.3.dev0) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.3.dev0) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.3.dev0) (2.27.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.3.dev0) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.3.dev0) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.3.dev0) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.3.dev0) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm==0.9.3.dev0) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.3.dev0) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.3.dev0) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.3.dev0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.3.dev0) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm==0.9.3.dev0) (1.3.0)\n","Building wheels for collected packages: timm\n","  Building wheel for timm (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for timm: filename=timm-0.9.3.dev0-py3-none-any.whl size=2183135 sha256=5fde3b82f3b26eb65ccd37c16f596d870dd20b418dfe533cbc5b85efdc52d64d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-n3d1lnrh/wheels/ed/07/8c/d16ff40e1a6ab5eff4240181152d83e10a933e1973397a1fec\n","Successfully built timm\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 timm-0.9.3.dev0\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/rwightman/pytorch-image-models"],"metadata":{"id":"ClPz2MqYtpWY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mv small_dog_cat_dataset/ pytorch-image-models/"],"metadata":{"id":"U7hfNqTrt5DA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd pytorch-image-models/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5sONyD4huPfY","outputId":"64cae41e-5472-4635-b48a-32572917a78c","executionInfo":{"status":"ok","timestamp":1687705109655,"user_tz":-420,"elapsed":18,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/pytorch-image-models\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"AjNVjKmg2Mq2"}},{"cell_type":"code","source":["!export NCCL_DEBUG=INFO"],"metadata":{"id":"Us-FVH2w5tu-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EfficientNet-B2\n","!python train.py ./small_dog_cat_dataset/ --model efficientnet_b2 --pretrained --num-classes 2 --batch-size 2 --sched step --epochs 2 --decay-epochs 1 --decay-rate .9 --opt adamp --opt-eps .001 -j 8 --warmup-lr 1e-5 --weight-decay 1e-5 --lr 5e-5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4uDn-kqruBT9","outputId":"731b4385-f7cd-4306-9bd7-2453c4ec9b29","executionInfo":{"status":"ok","timestamp":1687705591083,"user_tz":-420,"elapsed":422306,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training with a single process on 1 device (cuda:0).\n","Loading pretrained weights from Hugging Face hub (timm/efficientnet_b2.ra_in1k)\n","[timm/efficientnet_b2.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n","Model efficientnet_b2 created, param count:7703812\n","Data processing configuration for current model + dataset:\n","\tinput_size: (3, 256, 256)\n","\tinterpolation: bicubic\n","\tmean: (0.485, 0.456, 0.406)\n","\tstd: (0.229, 0.224, 0.225)\n","\tcrop_pct: 1.0\n","\tcrop_mode: center\n","AMP not enabled. Training in float32.\n","/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Scheduled epochs: 2. LR stepped per epoch.\n","Train: 0 [   0/1000 (  0%)]  Loss: 0.499 (0.499)  Time: 1.493s,    1.34/s  (1.493s,    1.34/s)  LR: 1.000e-05  Data: 0.646 (0.646)\n","Train: 0 [  50/1000 (  5%)]  Loss: 3.47 (1.28)  Time: 0.218s,    9.17/s  (0.173s,   11.57/s)  LR: 1.000e-05  Data: 0.003 (0.015)\n","Train: 0 [ 100/1000 ( 10%)]  Loss: 0.683 (1.30)  Time: 0.145s,   13.84/s  (0.172s,   11.61/s)  LR: 1.000e-05  Data: 0.003 (0.009)\n","Train: 0 [ 150/1000 ( 15%)]  Loss: 0.336 (1.22)  Time: 0.218s,    9.19/s  (0.163s,   12.27/s)  LR: 1.000e-05  Data: 0.009 (0.007)\n","Train: 0 [ 200/1000 ( 20%)]  Loss: 1.95 (1.20)  Time: 0.142s,   14.10/s  (0.165s,   12.10/s)  LR: 1.000e-05  Data: 0.003 (0.006)\n","Train: 0 [ 250/1000 ( 25%)]  Loss: 0.316 (1.19)  Time: 0.214s,    9.33/s  (0.163s,   12.31/s)  LR: 1.000e-05  Data: 0.010 (0.006)\n","Train: 0 [ 300/1000 ( 30%)]  Loss: 1.87 (1.16)  Time: 0.139s,   14.42/s  (0.164s,   12.22/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 350/1000 ( 35%)]  Loss: 2.51 (1.16)  Time: 0.589s,    3.39/s  (0.175s,   11.45/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 400/1000 ( 40%)]  Loss: 1.47 (1.15)  Time: 0.135s,   14.78/s  (0.171s,   11.67/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 450/1000 ( 45%)]  Loss: 0.425 (1.12)  Time: 0.139s,   14.41/s  (0.172s,   11.60/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 500/1000 ( 50%)]  Loss: 0.229 (1.11)  Time: 0.136s,   14.76/s  (0.169s,   11.83/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 550/1000 ( 55%)]  Loss: 1.70 (1.11)  Time: 0.144s,   13.91/s  (0.170s,   11.76/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 600/1000 ( 60%)]  Loss: 1.55 (1.11)  Time: 0.137s,   14.56/s  (0.167s,   11.95/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 650/1000 ( 65%)]  Loss: 0.207 (1.13)  Time: 0.137s,   14.60/s  (0.168s,   11.89/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 700/1000 ( 70%)]  Loss: 1.43 (1.10)  Time: 0.145s,   13.75/s  (0.166s,   12.04/s)  LR: 1.000e-05  Data: 0.010 (0.005)\n","Train: 0 [ 750/1000 ( 75%)]  Loss: 1.13 (1.11)  Time: 0.139s,   14.36/s  (0.167s,   11.98/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 800/1000 ( 80%)]  Loss: 0.229 (1.09)  Time: 0.140s,   14.30/s  (0.165s,   12.11/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 850/1000 ( 85%)]  Loss: 0.206 (1.07)  Time: 0.135s,   14.79/s  (0.166s,   12.06/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 900/1000 ( 90%)]  Loss: 1.36 (1.07)  Time: 0.135s,   14.80/s  (0.165s,   12.15/s)  LR: 1.000e-05  Data: 0.003 (0.005)\n","Train: 0 [ 950/1000 ( 95%)]  Loss: 0.827 (1.06)  Time: 0.134s,   14.93/s  (0.165s,   12.10/s)  LR: 1.000e-05  Data: 0.002 (0.005)\n","Test: [   0/1299]  Time: 0.689 (0.689)  Loss:   0.005 ( 0.005)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)\n","Test: [  50/1299]  Time: 0.027 (0.039)  Loss:   0.809 ( 1.042)  Acc@1:  50.000 ( 70.588)  Acc@5: 100.000 (100.000)\n","Test: [ 100/1299]  Time: 0.061 (0.042)  Loss:   2.023 ( 1.011)  Acc@1:   0.000 ( 69.307)  Acc@5: 100.000 (100.000)\n","Test: [ 150/1299]  Time: 0.055 (0.043)  Loss:   1.761 ( 1.026)  Acc@1:  50.000 ( 67.219)  Acc@5: 100.000 (100.000)\n","Test: [ 200/1299]  Time: 0.029 (0.043)  Loss:   2.558 ( 0.967)  Acc@1:   0.000 ( 68.905)  Acc@5: 100.000 (100.000)\n","Test: [ 250/1299]  Time: 0.035 (0.041)  Loss:   0.080 ( 0.897)  Acc@1: 100.000 ( 70.916)  Acc@5: 100.000 (100.000)\n","Test: [ 300/1299]  Time: 0.025 (0.038)  Loss:   0.179 ( 0.915)  Acc@1: 100.000 ( 71.262)  Acc@5: 100.000 (100.000)\n","Test: [ 350/1299]  Time: 0.024 (0.036)  Loss:   2.312 ( 0.946)  Acc@1:   0.000 ( 70.228)  Acc@5: 100.000 (100.000)\n","Test: [ 400/1299]  Time: 0.026 (0.035)  Loss:   0.425 ( 0.934)  Acc@1: 100.000 ( 69.327)  Acc@5: 100.000 (100.000)\n","Test: [ 450/1299]  Time: 0.025 (0.034)  Loss:   0.490 ( 0.937)  Acc@1:  50.000 ( 69.401)  Acc@5: 100.000 (100.000)\n","Test: [ 500/1299]  Time: 0.025 (0.033)  Loss:   4.362 ( 0.937)  Acc@1:  50.000 ( 69.760)  Acc@5: 100.000 (100.000)\n","Test: [ 550/1299]  Time: 0.027 (0.032)  Loss:   0.894 ( 0.967)  Acc@1:  50.000 ( 69.601)  Acc@5: 100.000 (100.000)\n","Test: [ 600/1299]  Time: 0.025 (0.032)  Loss:   0.127 ( 0.978)  Acc@1: 100.000 ( 69.218)  Acc@5: 100.000 (100.000)\n","Test: [ 650/1299]  Time: 0.045 (0.033)  Loss:   1.139 ( 0.981)  Acc@1:  50.000 ( 69.124)  Acc@5: 100.000 (100.000)\n","Test: [ 700/1299]  Time: 0.031 (0.033)  Loss:   3.555 ( 1.009)  Acc@1:  50.000 ( 68.759)  Acc@5: 100.000 (100.000)\n","Test: [ 750/1299]  Time: 0.031 (0.034)  Loss:   1.331 ( 1.011)  Acc@1:   0.000 ( 68.509)  Acc@5: 100.000 (100.000)\n","Test: [ 800/1299]  Time: 0.026 (0.034)  Loss:   0.218 ( 1.029)  Acc@1: 100.000 ( 68.477)  Acc@5: 100.000 (100.000)\n","Test: [ 850/1299]  Time: 0.024 (0.034)  Loss:   0.059 ( 1.010)  Acc@1: 100.000 ( 68.919)  Acc@5: 100.000 (100.000)\n","Test: [ 900/1299]  Time: 0.026 (0.033)  Loss:   0.074 ( 1.000)  Acc@1: 100.000 ( 69.312)  Acc@5: 100.000 (100.000)\n","Test: [ 950/1299]  Time: 0.024 (0.033)  Loss:   1.126 ( 0.979)  Acc@1:  50.000 ( 69.821)  Acc@5: 100.000 (100.000)\n","Test: [1000/1299]  Time: 0.026 (0.033)  Loss:   0.011 ( 0.961)  Acc@1: 100.000 ( 70.280)  Acc@5: 100.000 (100.000)\n","Test: [1050/1299]  Time: 0.029 (0.032)  Loss:   0.003 ( 0.946)  Acc@1: 100.000 ( 70.599)  Acc@5: 100.000 (100.000)\n","Test: [1100/1299]  Time: 0.027 (0.032)  Loss:   0.354 ( 0.916)  Acc@1: 100.000 ( 71.435)  Acc@5: 100.000 (100.000)\n","Test: [1150/1299]  Time: 0.044 (0.032)  Loss:   0.051 ( 0.906)  Acc@1: 100.000 ( 71.764)  Acc@5: 100.000 (100.000)\n","Test: [1200/1299]  Time: 0.059 (0.032)  Loss:   0.464 ( 0.885)  Acc@1:  50.000 ( 72.523)  Acc@5: 100.000 (100.000)\n","Test: [1250/1299]  Time: 0.036 (0.033)  Loss:   3.152 ( 0.876)  Acc@1:  50.000 ( 72.902)  Acc@5: 100.000 (100.000)\n","Test: [1299/1299]  Time: 0.019 (0.033)  Loss:   0.396 ( 0.861)  Acc@1:  50.000 ( 73.231)  Acc@5: 100.000 (100.000)\n","Current checkpoints:\n"," ('./output/train/20230625-145935-efficientnet_b2-256/checkpoint-0.pth.tar', 73.23076923076923)\n","\n","Train: 1 [   0/1000 (  0%)]  Loss: 1.33 (1.33)  Time: 0.359s,    5.58/s  (0.359s,    5.58/s)  LR: 1.800e-05  Data: 0.147 (0.147)\n","Train: 1 [  50/1000 (  5%)]  Loss: 0.562 (1.04)  Time: 0.134s,   14.97/s  (0.144s,   13.91/s)  LR: 1.800e-05  Data: 0.002 (0.006)\n","Train: 1 [ 100/1000 ( 10%)]  Loss: 0.228 (0.951)  Time: 0.131s,   15.23/s  (0.163s,   12.26/s)  LR: 1.800e-05  Data: 0.002 (0.006)\n","Train: 1 [ 150/1000 ( 15%)]  Loss: 2.50 (0.989)  Time: 0.138s,   14.54/s  (0.155s,   12.93/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 200/1000 ( 20%)]  Loss: 3.25 (0.981)  Time: 0.136s,   14.75/s  (0.162s,   12.37/s)  LR: 1.800e-05  Data: 0.002 (0.005)\n","Train: 1 [ 250/1000 ( 25%)]  Loss: 1.70 (0.952)  Time: 0.136s,   14.70/s  (0.157s,   12.75/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 300/1000 ( 30%)]  Loss: 1.12 (0.943)  Time: 0.146s,   13.70/s  (0.161s,   12.40/s)  LR: 1.800e-05  Data: 0.002 (0.005)\n","Train: 1 [ 350/1000 ( 35%)]  Loss: 0.258 (0.964)  Time: 0.137s,   14.58/s  (0.158s,   12.67/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 400/1000 ( 40%)]  Loss: 0.241 (0.956)  Time: 0.135s,   14.77/s  (0.161s,   12.43/s)  LR: 1.800e-05  Data: 0.002 (0.005)\n","Train: 1 [ 450/1000 ( 45%)]  Loss: 0.663 (0.953)  Time: 0.132s,   15.11/s  (0.158s,   12.64/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 500/1000 ( 50%)]  Loss: 0.494 (0.929)  Time: 0.231s,    8.67/s  (0.161s,   12.46/s)  LR: 1.800e-05  Data: 0.012 (0.005)\n","Train: 1 [ 550/1000 ( 55%)]  Loss: 0.368 (0.912)  Time: 0.139s,   14.39/s  (0.159s,   12.61/s)  LR: 1.800e-05  Data: 0.005 (0.005)\n","Train: 1 [ 600/1000 ( 60%)]  Loss: 0.760 (0.897)  Time: 0.229s,    8.73/s  (0.160s,   12.49/s)  LR: 1.800e-05  Data: 0.009 (0.005)\n","Train: 1 [ 650/1000 ( 65%)]  Loss: 0.894 (0.888)  Time: 0.132s,   15.18/s  (0.158s,   12.63/s)  LR: 1.800e-05  Data: 0.002 (0.005)\n","Train: 1 [ 700/1000 ( 70%)]  Loss: 1.80 (0.880)  Time: 0.202s,    9.91/s  (0.159s,   12.55/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 750/1000 ( 75%)]  Loss: 1.33 (0.883)  Time: 0.133s,   15.03/s  (0.158s,   12.63/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Train: 1 [ 800/1000 ( 80%)]  Loss: 0.368 (0.876)  Time: 0.235s,    8.52/s  (0.159s,   12.58/s)  LR: 1.800e-05  Data: 0.010 (0.005)\n","Train: 1 [ 850/1000 ( 85%)]  Loss: 0.279 (0.867)  Time: 0.135s,   14.77/s  (0.159s,   12.61/s)  LR: 1.800e-05  Data: 0.002 (0.005)\n","Train: 1 [ 900/1000 ( 90%)]  Loss: 0.284 (0.862)  Time: 0.221s,    9.05/s  (0.159s,   12.56/s)  LR: 1.800e-05  Data: 0.016 (0.005)\n","Train: 1 [ 950/1000 ( 95%)]  Loss: 0.309 (0.857)  Time: 0.165s,   12.11/s  (0.159s,   12.59/s)  LR: 1.800e-05  Data: 0.003 (0.005)\n","Test: [   0/1299]  Time: 0.262 (0.262)  Loss:   0.001 ( 0.001)  Acc@1: 100.000 (100.000)  Acc@5: 100.000 (100.000)\n","Test: [  50/1299]  Time: 0.026 (0.047)  Loss:   0.217 ( 0.687)  Acc@1: 100.000 ( 78.431)  Acc@5: 100.000 (100.000)\n","Test: [ 100/1299]  Time: 0.027 (0.037)  Loss:   0.846 ( 0.656)  Acc@1:   0.000 ( 77.723)  Acc@5: 100.000 (100.000)\n","Test: [ 150/1299]  Time: 0.026 (0.033)  Loss:   2.287 ( 0.638)  Acc@1:  50.000 ( 78.146)  Acc@5: 100.000 (100.000)\n","Test: [ 200/1299]  Time: 0.026 (0.032)  Loss:   2.000 ( 0.700)  Acc@1:   0.000 ( 76.368)  Acc@5: 100.000 (100.000)\n","Test: [ 250/1299]  Time: 0.027 (0.031)  Loss:   0.083 ( 0.721)  Acc@1: 100.000 ( 76.494)  Acc@5: 100.000 (100.000)\n","Test: [ 300/1299]  Time: 0.029 (0.030)  Loss:   0.316 ( 0.767)  Acc@1: 100.000 ( 75.581)  Acc@5: 100.000 (100.000)\n","Test: [ 350/1299]  Time: 0.024 (0.030)  Loss:   3.636 ( 0.765)  Acc@1:  50.000 ( 75.641)  Acc@5: 100.000 (100.000)\n","Test: [ 400/1299]  Time: 0.027 (0.029)  Loss:   0.286 ( 0.738)  Acc@1: 100.000 ( 75.935)  Acc@5: 100.000 (100.000)\n","Test: [ 450/1299]  Time: 0.048 (0.030)  Loss:   1.211 ( 0.724)  Acc@1:  50.000 ( 75.721)  Acc@5: 100.000 (100.000)\n","Test: [ 500/1299]  Time: 0.053 (0.031)  Loss:   1.582 ( 0.705)  Acc@1:  50.000 ( 76.148)  Acc@5: 100.000 (100.000)\n","Test: [ 550/1299]  Time: 0.046 (0.032)  Loss:   0.610 ( 0.714)  Acc@1:  50.000 ( 75.499)  Acc@5: 100.000 (100.000)\n","Test: [ 600/1299]  Time: 0.026 (0.033)  Loss:   0.213 ( 0.714)  Acc@1: 100.000 ( 75.208)  Acc@5: 100.000 (100.000)\n","Test: [ 650/1299]  Time: 0.026 (0.033)  Loss:   0.665 ( 0.707)  Acc@1:  50.000 ( 75.499)  Acc@5: 100.000 (100.000)\n","Test: [ 700/1299]  Time: 0.026 (0.032)  Loss:   0.877 ( 0.706)  Acc@1:  50.000 ( 75.963)  Acc@5: 100.000 (100.000)\n","Test: [ 750/1299]  Time: 0.025 (0.032)  Loss:   0.276 ( 0.702)  Acc@1: 100.000 ( 75.899)  Acc@5: 100.000 (100.000)\n","Test: [ 800/1299]  Time: 0.025 (0.031)  Loss:   1.587 ( 0.694)  Acc@1:   0.000 ( 75.968)  Acc@5: 100.000 (100.000)\n","Test: [ 850/1299]  Time: 0.025 (0.031)  Loss:   0.133 ( 0.697)  Acc@1: 100.000 ( 75.558)  Acc@5: 100.000 (100.000)\n","Test: [ 900/1299]  Time: 0.026 (0.031)  Loss:   0.227 ( 0.706)  Acc@1: 100.000 ( 75.361)  Acc@5: 100.000 (100.000)\n","Test: [ 950/1299]  Time: 0.024 (0.030)  Loss:   0.113 ( 0.711)  Acc@1: 100.000 ( 75.289)  Acc@5: 100.000 (100.000)\n","Test: [1000/1299]  Time: 0.055 (0.031)  Loss:   0.009 ( 0.713)  Acc@1: 100.000 ( 75.375)  Acc@5: 100.000 (100.000)\n","Test: [1050/1299]  Time: 0.025 (0.031)  Loss:   0.001 ( 0.716)  Acc@1: 100.000 ( 75.595)  Acc@5: 100.000 (100.000)\n","Test: [1100/1299]  Time: 0.064 (0.033)  Loss:   1.268 ( 0.706)  Acc@1:  50.000 ( 75.704)  Acc@5: 100.000 (100.000)\n","Test: [1150/1299]  Time: 0.091 (0.034)  Loss:   0.230 ( 0.709)  Acc@1: 100.000 ( 75.717)  Acc@5: 100.000 (100.000)\n","Test: [1200/1299]  Time: 0.027 (0.035)  Loss:   0.511 ( 0.703)  Acc@1:  50.000 ( 75.729)  Acc@5: 100.000 (100.000)\n","Test: [1250/1299]  Time: 0.024 (0.035)  Loss:   1.494 ( 0.700)  Acc@1:  50.000 ( 75.739)  Acc@5: 100.000 (100.000)\n","Test: [1299/1299]  Time: 0.017 (0.034)  Loss:   0.218 ( 0.694)  Acc@1: 100.000 ( 76.115)  Acc@5: 100.000 (100.000)\n","Current checkpoints:\n"," ('./output/train/20230625-145935-efficientnet_b2-256/checkpoint-1.pth.tar', 76.11538461538461)\n"," ('./output/train/20230625-145935-efficientnet_b2-256/checkpoint-0.pth.tar', 73.23076923076923)\n","\n","*** Best metric: 76.11538461538461 (epoch 1)\n"]}]},{"cell_type":"markdown","source":["# Searching for models"],"metadata":{"id":"VAY3x6n3FrKr"}},{"cell_type":"code","source":["import timm\n","\n","timm.list_models('*vit*')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEbPuj17FwXm","executionInfo":{"status":"ok","timestamp":1688044850570,"user_tz":-420,"elapsed":9,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"5c3bea74-27e5-45d3-98e9-eb996cf7ea76"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'davit_base',\n"," 'davit_giant',\n"," 'davit_huge',\n"," 'davit_large',\n"," 'davit_small',\n"," 'davit_tiny',\n"," 'flexivit_base',\n"," 'flexivit_large',\n"," 'flexivit_small',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'levit_384_s8',\n"," 'levit_512',\n"," 'levit_512_s8',\n"," 'levit_512d',\n"," 'levit_conv_128',\n"," 'levit_conv_128s',\n"," 'levit_conv_192',\n"," 'levit_conv_256',\n"," 'levit_conv_256d',\n"," 'levit_conv_384',\n"," 'levit_conv_384_s8',\n"," 'levit_conv_512',\n"," 'levit_conv_512_s8',\n"," 'levit_conv_512d',\n"," 'maxvit_base_tf_224',\n"," 'maxvit_base_tf_384',\n"," 'maxvit_base_tf_512',\n"," 'maxvit_large_tf_224',\n"," 'maxvit_large_tf_384',\n"," 'maxvit_large_tf_512',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_base_rw_224',\n"," 'maxvit_rmlp_base_rw_384',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_tf_224',\n"," 'maxvit_small_tf_384',\n"," 'maxvit_small_tf_512',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_tiny_tf_224',\n"," 'maxvit_tiny_tf_384',\n"," 'maxvit_tiny_tf_512',\n"," 'maxvit_xlarge_tf_224',\n"," 'maxvit_xlarge_tf_384',\n"," 'maxvit_xlarge_tf_512',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'maxxvitv2_nano_rw_256',\n"," 'maxxvitv2_rmlp_base_rw_224',\n"," 'maxxvitv2_rmlp_base_rw_384',\n"," 'maxxvitv2_rmlp_large_rw_224',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_200',\n"," 'mvitv2_base',\n"," 'mvitv2_base_cls',\n"," 'mvitv2_huge_cls',\n"," 'mvitv2_large',\n"," 'mvitv2_large_cls',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'samvit_base_patch16',\n"," 'samvit_huge_patch16',\n"," 'samvit_large_patch16',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch14_dinov2',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_clip_224',\n"," 'vit_base_patch16_clip_384',\n"," 'vit_base_patch16_gap_224',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch16_xp_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_clip_224',\n"," 'vit_base_patch32_clip_384',\n"," 'vit_base_patch32_clip_448',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_clip_224',\n"," 'vit_giant_patch14_dinov2',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_gigantic_patch14_clip_224',\n"," 'vit_gigantic_patch16_224_ijepa',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_ijepa',\n"," 'vit_huge_patch14_clip_224',\n"," 'vit_huge_patch14_clip_336',\n"," 'vit_huge_patch14_xp_224',\n"," 'vit_huge_patch16_448_ijepa',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_clip_224',\n"," 'vit_large_patch14_clip_336',\n"," 'vit_large_patch14_dinov2',\n"," 'vit_large_patch14_xp_224',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_384',\n"," 'vit_medium_patch16_gap_240',\n"," 'vit_medium_patch16_gap_256',\n"," 'vit_medium_patch16_gap_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224',\n"," 'vit_small_patch14_dinov2',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_384']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["timm.list_models('*b3a')[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGo3WHeeF3xt","executionInfo":{"status":"ok","timestamp":1687705602067,"user_tz":-420,"elapsed":21,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"d874a397-62a6-4aef-efca-7584195dcfc2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['efficientnet_b3a']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["timm.list_models('resne*t*', pretrained=True)[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l1yIGHe_F8dy","executionInfo":{"status":"ok","timestamp":1687705606669,"user_tz":-420,"elapsed":10,"user":{"displayName":"Minh Hùng An","userId":"12219570561405750876"}},"outputId":"b8655824-94da-4dda-99b9-69708627e10d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['resnest14d.gluon_in1k',\n"," 'resnest26d.gluon_in1k',\n"," 'resnest50d.in1k',\n"," 'resnest50d_1s4x24d.in1k',\n"," 'resnest50d_4s2x40d.in1k',\n"," 'resnest101e.in1k',\n"," 'resnest200e.in1k',\n"," 'resnest269e.in1k',\n"," 'resnet10t.c3_in1k',\n"," 'resnet14t.c3_in1k']"]},"metadata":{},"execution_count":14}]}]}